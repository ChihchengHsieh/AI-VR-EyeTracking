{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing if we can load the file from D:\\\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, we can load the data in D:\\\n",
    "\n",
    "triage_df = pd.read_csv(\"D:/AI-VR dataset/MIMIC-IV ED/triage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>acuity</th>\n",
       "      <th>chiefcomplaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15585360</td>\n",
       "      <td>37573921</td>\n",
       "      <td>97.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17192424</td>\n",
       "      <td>34160628</td>\n",
       "      <td>98.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15248757</td>\n",
       "      <td>32172727</td>\n",
       "      <td>97.1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16648037</td>\n",
       "      <td>38946064</td>\n",
       "      <td>98.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13492931</td>\n",
       "      <td>39828574</td>\n",
       "      <td>100.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   stay_id  temperature  heartrate  resprate  o2sat    sbp   dbp  \\\n",
       "0    15585360  37573921         97.0       87.0      18.0  100.0  150.0  71.0   \n",
       "1    17192424  34160628         98.6       82.0       NaN  100.0  111.0  81.0   \n",
       "2    15248757  32172727         97.1      112.0      20.0  100.0  147.0  97.0   \n",
       "3    16648037  38946064         98.5       59.0      18.0   99.0  160.0  86.0   \n",
       "4    13492931  39828574        100.6       90.0      16.0   96.0  107.0  55.0   \n",
       "\n",
       "   pain  acuity chiefcomplaint  \n",
       "0  10.0     3.0              \n",
       "1   3.0     3.0                \n",
       "2   8.0     4.0               \n",
       "3   2.0     2.0                \n",
       "4   0.0     3.0              '  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triage_df.head(5)\n",
    "\n",
    "####################\n",
    "# Qeustions:\n",
    "# 1. Which field do we need? (Should be able to remove chiefcomplaint)\n",
    "# 2. How to deal with missing value?\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the path for ED, Clinical and Image\n",
    "\n",
    "ED_FOLDER_PATH = \"D:/AI-VR dataset/MIMIC-IV ED\"\n",
    "CLINICAL_FOLDER_PATH = \"D:/AI-VR dataset/MIMIC-IV Clinical Database\"\n",
    "CXR_FOLDER_PATH = \"D:/AI-VR dataset/MIMIC-CXR-JPG\"\n",
    "EYETRACKING_FOLDER_PATH = \"D:/AI-VR dataset/eye-gaze-data-for-chest-x-rays-1.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which data I need to load \n",
    "# 1. Eye tracking data\n",
    "# 2. Triage\n",
    "# 3. \n",
    "# Start loading data and perform preprocessing.\n",
    "\n",
    "###### Some other important table ######\n",
    "# 1. Diagnosis <ED & Clinical-Hosp> (But we have label already in eye_gaze dataset)\n",
    "# 2. We have \"insurance, language, marital_status, ethnicity\" in admissions table <Clinical-Core>\n",
    "# 3. We have \"gender, anchor_age\" in patients table <Clinical-Core>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the stayId in eye tracking master_sheet to find the information in the triage.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_df = pd.read_csv(\"D:/AI-VR dataset/MIMIC-IV ED/triage.csv\")\n",
    "eye_gaze_master_sheet = pd.read_csv(\"D:/AI-VR dataset/eye-gaze-data-for-chest-x-rays-1.0.0/master_sheet.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the basic extraction, we need to select the eye tracking dataset.\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class TabularData():\n",
    "    class _ED (Enum):\n",
    "        edstays = \"edstays\"\n",
    "        medrecon = \"medrecon\"\n",
    "        pyxis = \"pyxis\"\n",
    "        triage = \"triage\"\n",
    "        vitalsign = \"vitalsign\"\n",
    "\n",
    "    class _Clinical():\n",
    "        class _Core(Enum):\n",
    "            admissions = \"admissions\"\n",
    "            patients = \"patients\"\n",
    "            transfers = \"transfers\"\n",
    "\n",
    "        class _Hosp (Enum):\n",
    "            poe_detail = \"poe_detail\"\n",
    "            pharmacy = \"pharmacy\"\n",
    "            emar = \"emar\"\n",
    "            microbiologyevents = \"microbiologyevents\"\n",
    "            labevents = \"labevents\"\n",
    "            d_labitems = \"d_labitems\"\n",
    "            prescriptions = \"prescriptions\"\n",
    "            procedures_icd = \"procedures_icd\"\n",
    "            poe = \"poe\"\n",
    "            d_hcpcs = \"d_hcpcs\"\n",
    "            diagnoses_icd = \"diagnoses_icd\"\n",
    "            services = \"services\"\n",
    "            hcpcsevents = \"hcpcsevents\"\n",
    "            drgcodes = \"drgcodes\"\n",
    "            d_icd_diagnoses = \"d_icd_diagnoses\"\n",
    "            d_icd_procedures = \"d_icd_procedures\"\n",
    "            emar_detail = \"emar_detail\"\n",
    "\n",
    "        class _ICU(Enum):\n",
    "            d_items = \"d_items\"\n",
    "            procedureevents = \"procedureevents\"\n",
    "            inputevents = \"inputevents\"\n",
    "            datetimeevents = \"datetimeevents\"\n",
    "            chartevents = \"chartevents\"\n",
    "            outputevents = \"outputevents\"\n",
    "            icustays = \"icustays\"\n",
    "\n",
    "        Core = _Core\n",
    "        Hosp = _Hosp\n",
    "        ICU = _ICU\n",
    "\n",
    "    class _EyeGaze(Enum):\n",
    "        master_sheet = \"master_sheet\"\n",
    "        fixations = \"fixations\"\n",
    "        eye_gaze = \"eye_gaze\"\n",
    "        bounding_boxes = \"bounding_boxes\"\n",
    "\n",
    "    Clinical = _Clinical\n",
    "    EyeGaze = _EyeGaze\n",
    "    ED = _ED\n",
    "\n",
    "\n",
    "class TranscriptsData(Enum):\n",
    "    EyeGaze = \"EyeGaze\"\n",
    "\n",
    "\n",
    "class SegmentationData(Enum):\n",
    "    EyeGaze = \"EyeGaze\"\n",
    "\n",
    "\n",
    "class CXRData(Enum):\n",
    "    JPEG = \"JPEG\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def load_tabular_data(tabular_data):\n",
    "    linking_features = [\"stay_id\", \"subject_id\", \"patient_id\", \"dicom_id\"] # order through priority\n",
    "    all_dataframes = []\n",
    "\n",
    "    # distribute to different data folder\n",
    "    for sheet_name in tabular_data:\n",
    "\n",
    "        # Dealing with Clinical dataset\n",
    "        if (sheet_name in TabularData._Clinical._Core):\n",
    "            # load the data from clinical path, we will also have the value (name of the csv).\n",
    "            all_dataframes.append(pd.read_csv(\n",
    "                f\"{CLINICAL_FOLDER_PATH}/core/{sheet_name.value}.csv\"))\n",
    "        elif (sheet_name in TabularData._Clinical._Hosp):\n",
    "            all_dataframes.append(pd.read_csv(\n",
    "                f\"{CLINICAL_FOLDER_PATH}/hosp/{sheet_name.value}.csv\"))\n",
    "        elif (sheet_name in TabularData._Clinical._ICU):\n",
    "            all_dataframes.append(pd.read_csv(\n",
    "                f\"{CLINICAL_FOLDER_PATH}/icu/{sheet_name.value}.csv\"))\n",
    "\n",
    "        # Dealing with ED dataset.\n",
    "        elif (sheet_name in TabularData._ED):\n",
    "            all_dataframes.append(pd.read_csv(\n",
    "                f\"{ED_FOLDER_PATH}/{sheet_name.value}.csv\"))\n",
    "\n",
    "        # Dealing with eye gaze dataset\n",
    "        elif (sheet_name in TabularData._EyeGaze):\n",
    "            all_dataframes.append(pd.read_csv(\n",
    "                f\"{EYETRACKING_FOLDER_PATH}/{sheet_name.value}.csv\"))\n",
    "\n",
    "    if (len(all_dataframes) > 1):\n",
    "        # Perform join table\n",
    "        main_table: pd.DataFrame = all_dataframes[0]\n",
    "        join_tables: List(pd.DataFrame) = all_dataframes[1:]\n",
    "\n",
    "        # checking if the main_table has at least one linking_code:\n",
    "        if not any([linking_feature in main_table.columns for linking_feature in linking_features]):\n",
    "            raise Exception(\"No available linking feature in the\")\n",
    "\n",
    "        # if we have patient_id available but not the subject_id\n",
    "        if  (\"patient_id\" in main_table) and  (not \"subject_id\"  in main_table):\n",
    "            # add the subject_id column\n",
    "            main_table[\"subject_id\"] = main_table[\"patient_id\"]\n",
    "        \n",
    "        # if we have subject_id available but not the patient_id\n",
    "        if  (\"subject_id\" in main_table) and  (not \"patient_id\"  in main_table):\n",
    "            # add the subject_id column\n",
    "            main_table[\"patient_id\"] = main_table[\"subject_id\"]\n",
    "\n",
    "        for sheet_name, table_to_join in zip(tabular_data, join_tables):\n",
    "            for linking_feature in linking_features:\n",
    "                if linking_feature in table_to_join.columns:\n",
    "                    main_table.join(table_to_join, linking_feature)\n",
    "                    print(f\"Table {sheet_name} has been joined through {linking_feature}\")\n",
    "                    break \n",
    "                \n",
    "                # If the last feature is not the linking feature as well.\n",
    "                if linking_feature == linking_features[-1]:\n",
    "                    print(f\"{sheet_name} doesn't have subjectId or patientId to join\")\n",
    "\n",
    "        return main_table\n",
    "    elif len(all_dataframes) == 0:\n",
    "        return all_dataframes[0]\n",
    "    else:\n",
    "        raise Exception(\"No table found.\")\n",
    "\n",
    "    # Then we join all the tables according to the patient and subjectId. Priority => subject > patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stay_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18492/2338876391.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_tabular_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTabularData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEyeGaze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounding_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTabularData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEyeGaze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_sheet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTabularData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medstays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTabularData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClinical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madmissions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTabularData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClinical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrgcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTabularData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClinical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mICU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputevents\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18492/3713369031.py\u001b[0m in \u001b[0;36mload_tabular_data\u001b[1;34m(tabular_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlinking_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinking_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlinking_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtable_to_join\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                     \u001b[0mmain_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_to_join\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinking_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table {sheet_name} has been joined through {linking_feature}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   9097\u001b[0m         \u001b[1;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9098\u001b[0m         \"\"\"\n\u001b[1;32m-> 9099\u001b[1;33m         return self._join_compat(\n\u001b[0m\u001b[0;32m   9100\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9101\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   9128\u001b[0m                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9129\u001b[0m                 )\n\u001b[1;32m-> 9130\u001b[1;33m             return merge(\n\u001b[0m\u001b[0;32m   9131\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9132\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 106\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1119\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                     \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'stay_id'"
     ]
    }
   ],
   "source": [
    "df = load_tabular_data([TabularData.EyeGaze.bounding_boxes, TabularData.EyeGaze.master_sheet, TabularData.ED.edstays, TabularData.Clinical.Core.admissions, TabularData.Clinical.Hosp.drgcodes, TabularData.Clinical.ICU.inputevents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = [TabularData.EyeGaze.bounding_boxes, TabularData.EyeGaze.master_sheet, TabularData.ED.edstays, TabularData.Clinical.Core.admissions, TabularData.Clinical.Hosp.drgcodes, TabularData.Clinical.ICU.inputevents]\n",
    "\n",
    "linking_features = [\"stay_id\", \"subject_id\", \"patient_id\", \"dicom_id\"] # order through priority\n",
    "all_dataframes = []\n",
    "\n",
    "# distribute to different data folder\n",
    "for sheet_name in tabular_data:\n",
    "\n",
    "    # Dealing with Clinical dataset\n",
    "    if (sheet_name in TabularData._Clinical._Core):\n",
    "        # load the data from clinical path, we will also have the value (name of the csv).\n",
    "        all_dataframes.append(pd.read_csv(\n",
    "            f\"{CLINICAL_FOLDER_PATH}/core/{sheet_name.value}.csv\"))\n",
    "    elif (sheet_name in TabularData._Clinical._Hosp):\n",
    "        all_dataframes.append(pd.read_csv(\n",
    "            f\"{CLINICAL_FOLDER_PATH}/hosp/{sheet_name.value}.csv\"))\n",
    "    elif (sheet_name in TabularData._Clinical._ICU):\n",
    "        all_dataframes.append(pd.read_csv(\n",
    "            f\"{CLINICAL_FOLDER_PATH}/icu/{sheet_name.value}.csv\"))\n",
    "\n",
    "    # Dealing with ED dataset.\n",
    "    elif (sheet_name in TabularData._ED):\n",
    "        all_dataframes.append(pd.read_csv(\n",
    "            f\"{ED_FOLDER_PATH}/{sheet_name.value}.csv\"))\n",
    "\n",
    "    # Dealing with eye gaze dataset\n",
    "    elif (sheet_name in TabularData._EyeGaze):\n",
    "        all_dataframes.append(pd.read_csv(\n",
    "            f\"{EYETRACKING_FOLDER_PATH}/{sheet_name.value}.csv\"))\n",
    "\n",
    "if (len(all_dataframes) > 1):\n",
    "    # Perform join table\n",
    "    main_table: pd.DataFrame = all_dataframes[0]\n",
    "    join_tables: List(pd.DataFrame) = all_dataframes[1:]\n",
    "\n",
    "    # checking if the main_table has at least one linking_code:\n",
    "    if not any([linking_feature in main_table.columns for linking_feature in linking_features]):\n",
    "        raise Exception(\"No available linking feature in the\")\n",
    "\n",
    "    # if we have patient_id available but not the subject_id\n",
    "    if  (\"patient_id\" in main_table) and  (not \"subject_id\"  in main_table):\n",
    "        # add the subject_id column\n",
    "        main_table[\"subject_id\"] = main_table[\"patient_id\"]\n",
    "    \n",
    "    # if we have subject_id available but not the patient_id\n",
    "    if  (\"subject_id\" in main_table) and  (not \"patient_id\"  in main_table):\n",
    "        # add the subject_id column\n",
    "        main_table[\"patient_id\"] = main_table[\"subject_id\"]\n",
    "\n",
    "    for sheet_name, table_to_join in zip(tabular_data, join_tables):\n",
    "        for linking_feature in linking_features:\n",
    "            if linking_feature in table_to_join.columns:\n",
    "                main_table.join(table_to_join, linking_feature)\n",
    "                print(f\"Table {sheet_name} has been joined through {linking_feature}\")\n",
    "                break \n",
    "            \n",
    "            # If the last feature is not the linking feature as well.\n",
    "            if linking_feature == linking_features[-1]:\n",
    "                print(f\"{sheet_name} doesn't have subjectId or patientId to join\")\n",
    "    raise Exception(\"No table found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMICDataLoader():\n",
    "    def __init__(self, tabular_data=[], cxr_data=[], transcripts_data=[], segmentation_data=[]) -> None:\n",
    "        pass\n",
    "\n",
    "    def load_tabular_data(self, tabular_data):\n",
    "        # distribute to different data folder\n",
    "        for sheet_name in tabular_data:\n",
    "            if (sheet_name in TabularData._Clinical._Core): \n",
    "                pass\n",
    "            elif (sheet_name in TabularData._Clinical._Core):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "    def load_cxr_data(self, cxr_data):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "transfers_df_0dot4 = pd.read_csv(f\"transfers-0.4.csv.gz\", compression='gzip', header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662573"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transfers_df_0dot4[transfers_df_0dot4[\"eventtype\"] == \"ED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448972"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ED_edstays_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ED_FOLDER_PATH = \"E:/AI-VR dataset/MIMIC-IV ED\"\n",
    "ED_edstays_df = pd.read_csv(f\"{ED_FOLDER_PATH}/edstays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2192963"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transfers_df_0dot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TableData.Clinical is TableData._Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_ed_df = transfers_df_0dot4[transfers_df_0dot4[\"eventtype\"] == \"ED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_to_older_stay_id={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_to_older_stay_id.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for ed_stay_instance in ED_edstays_df.iloc:\n",
    "    subject_id = ed_stay_instance['subject_id']\n",
    "    matches_transfered = transfer_ed_df[\n",
    "        (transfer_ed_df['subject_id'] == subject_id) &\n",
    "        (transfer_ed_df['intime'] == ed_stay_instance['intime']) &\n",
    "        (transfer_ed_df['outtime'] == ed_stay_instance['outtime'])\n",
    "    ]\n",
    "\n",
    "    if (len(matches_transfered) > 0) and (not (matches_transfered.iloc[0]['transfer_id'] in new_to_older_stay_id.values())):\n",
    "        new_to_older_stay_id[ed_stay_instance['stay_id']\n",
    "                             ] = matches_transfered.iloc[0]['transfer_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'type' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26372/2710062313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTableData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClinical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTableData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClinical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'type' is not iterable"
     ]
    }
   ],
   "source": [
    "TableData.Clinical.Core in TableData.Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Core is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26372/1806495172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTableData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClinical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madmissions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Core is not JSON serializable"
     ]
    }
   ],
   "source": [
    "json.dumps(TableData.Clinical.Core.admissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ED.edstays: 'edstays'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TableData.ED.edstays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'Core'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TableData.Clinical.Core.patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep the data structure \n",
    "# 2. Let's check if we have the field that repetitive? Not really, we should be able to load the selected eye gaze data.\n",
    "# 3. I will use a data loader class to access the whole data.\n",
    "# 4. Firstly, download the reflex dataset, and check the difference btw eye-gaze and reflex.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9d14ce5063c5d8aaa62f42a22b56c5ab7a43293d440cad85867ad61e60e7912"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
